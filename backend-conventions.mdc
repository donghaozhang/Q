---
description:
globs:
alwaysApply: false
---
# Suna Backend Conventions

## Backend File Structure

```
backend/
├── agent/                            # Core Agent System
│   ├── tools/                        # Agent Tool Implementations
│   │   ├── data_providers/           # External Data Source Integrations
│   │   │   ├── __init__.py
│   │   │   ├── linkedin_provider.py  # LinkedIn API Integration
│   │   │   ├── tavily_provider.py    # Tavily Search Integration
│   │   │   ├── firecrawl_provider.py # Firecrawl Scraping Integration
│   │   │   ├── amazon_provider.py    # Amazon API Integration
│   │   │   └── rapidapi_provider.py  # RapidAPI Integrations
│   │   ├── browser_automation.py     # Playwright Browser Control
│   │   ├── code_execution.py         # Python Code Interpreter
│   │   ├── file_operations.py        # File System Operations
│   │   ├── web_search.py             # Web Search Capabilities
│   │   ├── api_integration.py        # External API Calls
│   │   └── __init__.py
│   ├── agent_manager.py              # Agent Lifecycle Management
│   ├── executor.py                   # Tool Execution Engine
│   ├── schemas.py                    # Pydantic Data Models
│   ├── prompts.py                    # Agent System Prompts
│   └── __init__.py
├── agentpress/                       # Agent Marketplace/Builder
│   ├── models/                       # Agent Templates and Configurations
│   │   ├── __init__.py
│   │   ├── agent_templates.py        # Predefined Agent Templates
│   │   ├── tool_configs.py           # Tool Configuration Models
│   │   └── marketplace_models.py     # Marketplace Data Models
│   ├── builder.py                    # Agent Builder Interface
│   ├── marketplace.py                # Agent Sharing Platform
│   ├── validator.py                  # Agent Configuration Validation
│   └── __init__.py
├── mcp_local/                        # Model Context Protocol Integration
│   ├── tools/                        # MCP Tool Implementations
│   │   ├── __init__.py
│   │   ├── browser_tool.py           # MCP Browser Automation
│   │   ├── file_tool.py              # MCP File Operations
│   │   ├── search_tool.py            # MCP Search Tool
│   │   └── api_tool.py               # MCP API Integration Tool
│   ├── providers/                    # MCP Service Providers
│   │   ├── __init__.py
│   │   ├── linkedin_mcp.py           # LinkedIn MCP Provider
│   │   ├── tavily_mcp.py             # Tavily MCP Provider
│   │   └── custom_mcp.py             # Custom MCP Implementations
│   ├── server.py                     # MCP Server Implementation
│   ├── client.py                     # MCP Client Interface
│   └── __init__.py
├── sandbox/                          # Secure Execution Environment
│   ├── docker/                       # Docker Configuration
│   │   ├── Dockerfile.agent          # Agent Container Configuration
│   │   ├── requirements.txt          # Agent Container Dependencies
│   │   └── entrypoint.sh             # Container Entry Point
│   ├── daytona/                      # Daytona Integration
│   │   ├── __init__.py
│   │   ├── client.py                 # Daytona API Client
│   │   ├── workspace.py              # Workspace Management
│   │   └── security.py               # Security Policies
│   ├── isolation.py                  # Sandbox Security Implementation
│   ├── resources.py                  # Resource Management and Limits
│   ├── monitor.py                    # Execution Monitoring
│   └── __init__.py
├── services/                         # Backend Services
│   ├── auth.py                       # Authentication Service
│   ├── llm.py                        # LLM Provider Integration
│   ├── storage.py                    # File Storage Service
│   ├── websocket.py                  # Real-time Communication
│   ├── cache.py                      # Redis Caching Service
│   ├── queue.py                      # Background Job Queue
│   └── __init__.py
├── supabase/                         # Database Integration
│   ├── migrations/                   # Database Schema Migrations
│   │   ├── 001_initial_schema.sql    # Initial Database Schema
│   │   ├── 002_agent_tables.sql      # Agent-related Tables
│   │   ├── 003_marketplace.sql       # Marketplace Tables
│   │   └── 004_analytics.sql         # Analytics Tables
│   ├── client.py                     # Supabase Client Configuration
│   ├── models.py                     # Database ORM Models
│   ├── queries.py                    # Database Query Helpers
│   └── __init__.py
├── utils/                            # Backend Utilities
│   ├── scripts/                      # Setup and Maintenance Scripts
│   │   ├── setup_database.py         # Database Setup Script
│   │   ├── migrate_data.py           # Data Migration Script
│   │   └── cleanup_old_data.py       # Data Cleanup Script
│   ├── logging.py                    # Logging Configuration
│   ├── validators.py                 # Input Validation Utilities
│   ├── decorators.py                 # Custom Decorators
│   ├── exceptions.py                 # Custom Exception Classes
│   └── __init__.py
├── tests/                            # Test Suite
│   ├── unit/                         # Unit Tests
│   │   ├── test_agents.py            # Agent System Tests
│   │   ├── test_tools.py             # Tool Tests
│   │   └── test_services.py          # Service Tests
│   ├── integration/                  # Integration Tests
│   │   ├── test_api.py               # API Integration Tests
│   │   ├── test_database.py          # Database Tests
│   │   └── test_mcp.py               # MCP Integration Tests
│   ├── fixtures/                     # Test Fixtures
│   └── conftest.py                   # Pytest Configuration
├── api.py                            # Main FastAPI Application
├── run_agent_background.py           # Background Agent Execution
├── list_mcp.py                       # MCP Tool Discovery
├── test_mcp_use.py                   # MCP Testing Utilities
├── test_custom_mcp.py                # Custom MCP Testing
├── requirements.txt                  # Python Dependencies
├── pyproject.toml                    # Poetry Configuration
├── .env                              # Environment Variables
├── .env.example                      # Environment Template
├── Dockerfile                        # Production Docker Image
├── docker-compose.yml                # Development Docker Setup
└── README.md                         # Backend Documentation
```

## FastAPI Application Structure

### Main Application (api.py)
```python
from fastapi import FastAPI, HTTPException, Depends, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import uvicorn

from services.auth import AuthService
from services.llm import LLMService
from agent.agent_manager import AgentManager
from supabase.client import get_supabase_client

app = FastAPI(
    title="Suna AI Agent API",
    description="Backend API for Suna AI Agent Platform",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS Configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "https://yourdomain.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Security
security = HTTPBearer()
auth_service = AuthService()

# Dependency Injection
async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Get current authenticated user from JWT token."""
    return await auth_service.get_current_user(credentials.credentials)

async def get_agent_manager():
    """Get agent manager instance."""
    return AgentManager()

# API Routes
@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy", "service": "suna-backend"}

@app.post("/api/threads")
async def create_thread(
    request: CreateThreadRequest,
    user=Depends(get_current_user),
    agent_manager=Depends(get_agent_manager)
):
    """Create a new conversation thread."""
    return await agent_manager.create_thread(user.id, request)

@app.post("/api/threads/{thread_id}/messages")
async def send_message(
    thread_id: str,
    request: SendMessageRequest,
    user=Depends(get_current_user),
    agent_manager=Depends(get_agent_manager)
):
    """Send a message to an agent thread."""
    return await agent_manager.process_message(thread_id, user.id, request)

@app.websocket("/ws/{thread_id}")
async def websocket_endpoint(websocket: WebSocket, thread_id: str):
    """WebSocket endpoint for real-time communication."""
    await websocket.accept()
    # WebSocket handling logic
    
if __name__ == "__main__":
    uvicorn.run(
        "api:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
```

### Agent Management System
```python
# agent/agent_manager.py
from typing import Dict, List, Optional, Any
import asyncio
import uuid
from datetime import datetime

from .executor import ToolExecutor
from .schemas import AgentConfig, ToolCall, Message
from services.llm import LLMService
from services.storage import StorageService
from sandbox.isolation import SandboxManager

class AgentManager:
    """Manages agent lifecycle and execution."""
    
    def __init__(self):
        self.llm_service = LLMService()
        self.storage_service = StorageService()
        self.sandbox_manager = SandboxManager()
        self.tool_executor = ToolExecutor()
        self.active_agents: Dict[str, Agent] = {}
    
    async def create_thread(self, user_id: str, config: CreateThreadRequest) -> Dict[str, Any]:
        """Create a new agent thread."""
        thread_id = str(uuid.uuid4())
        
        # Create agent instance
        agent = Agent(
            thread_id=thread_id,
            user_id=user_id,
            config=config.agent_config,
            tools=config.enabled_tools
        )
        
        # Initialize sandbox environment
        sandbox = await self.sandbox_manager.create_sandbox(thread_id)
        agent.sandbox = sandbox
        
        # Store in active agents
        self.active_agents[thread_id] = agent
        
        # Persist to database
        await self.storage_service.create_thread(thread_id, user_id, config)
        
        return {"thread_id": thread_id, "status": "created"}
    
    async def process_message(
        self, 
        thread_id: str, 
        user_id: str, 
        request: SendMessageRequest
    ) -> Dict[str, Any]:
        """Process a user message and generate agent response."""
        
        # Get or create agent
        agent = await self._get_or_load_agent(thread_id, user_id)
        
        # Add user message to context
        user_message = Message(
            id=str(uuid.uuid4()),
            thread_id=thread_id,
            role="user",
            content=request.content,
            created_at=datetime.utcnow()
        )
        
        agent.add_message(user_message)
        
        # Generate agent response
        response = await self._generate_agent_response(agent)
        
        # Execute any tool calls
        if response.tool_calls:
            tool_results = await self._execute_tools(agent, response.tool_calls)
            response.tool_results = tool_results
        
        # Store response
        agent.add_message(response)
        await self.storage_service.save_message(response)
        
        return {
            "message_id": response.id,
            "content": response.content,
            "tool_calls": response.tool_calls,
            "tool_results": response.tool_results
        }
    
    async def _generate_agent_response(self, agent: Agent) -> Message:
        """Generate LLM response for agent."""
        
        # Prepare conversation context
        context = self._build_conversation_context(agent)
        
        # Call LLM service
        llm_response = await self.llm_service.generate_response(
            messages=context,
            tools=agent.available_tools,
            model=agent.config.model
        )
        
        # Create response message
        response = Message(
            id=str(uuid.uuid4()),
            thread_id=agent.thread_id,
            role="assistant",
            content=llm_response.content,
            tool_calls=llm_response.tool_calls,
            created_at=datetime.utcnow()
        )
        
        return response
    
    async def _execute_tools(self, agent: Agent, tool_calls: List[ToolCall]) -> List[Dict[str, Any]]:
        """Execute tool calls in agent's sandbox."""
        
        results = []
        for tool_call in tool_calls:
            try:
                result = await self.tool_executor.execute(
                    tool_call=tool_call,
                    sandbox=agent.sandbox,
                    context=agent.get_context()
                )
                results.append({
                    "tool_call_id": tool_call.id,
                    "result": result,
                    "status": "success"
                })
            except Exception as e:
                results.append({
                    "tool_call_id": tool_call.id,
                    "error": str(e),
                    "status": "error"
                })
        
        return results
```

### Tool Execution System
```python
# agent/executor.py
from typing import Dict, Any, List
import importlib
import inspect
from abc import ABC, abstractmethod

from .schemas import ToolCall
from sandbox.isolation import Sandbox

class BaseTool(ABC):
    """Base class for all agent tools."""
    
    @property
    @abstractmethod
    def name(self) -> str:
        """Tool name identifier."""
        pass
    
    @property
    @abstractmethod
    def description(self) -> str:
        """Tool description for LLM."""
        pass
    
    @property
    @abstractmethod
    def parameters(self) -> Dict[str, Any]:
        """JSON schema for tool parameters."""
        pass
    
    @abstractmethod
    async def execute(self, sandbox: Sandbox, **kwargs) -> Any:
        """Execute the tool with given parameters."""
        pass

class ToolExecutor:
    """Executes agent tools in secure sandbox environments."""
    
    def __init__(self):
        self.tools: Dict[str, BaseTool] = {}
        self._load_tools()
    
    def _load_tools(self):
        """Dynamically load all available tools."""
        tool_modules = [
            "agent.tools.browser_automation",
            "agent.tools.file_operations",
            "agent.tools.web_search",
            "agent.tools.code_execution",
            "agent.tools.api_integration"
        ]
        
        for module_name in tool_modules:
            module = importlib.import_module(module_name)
            for name, obj in inspect.getmembers(module):
                if (inspect.isclass(obj) and 
                    issubclass(obj, BaseTool) and 
                    obj != BaseTool):
                    tool_instance = obj()
                    self.tools[tool_instance.name] = tool_instance
    
    async def execute(self, tool_call: ToolCall, sandbox: Sandbox, context: Dict[str, Any]) -> Any:
        """Execute a specific tool call."""
        
        if tool_call.function.name not in self.tools:
            raise ValueError(f"Unknown tool: {tool_call.function.name}")
        
        tool = self.tools[tool_call.function.name]
        
        # Parse tool arguments
        import json
        args = json.loads(tool_call.function.arguments)
        
        # Add context to arguments
        args["context"] = context
        
        # Execute tool in sandbox
        result = await tool.execute(sandbox, **args)
        
        return result
    
    def get_tool_schemas(self) -> List[Dict[str, Any]]:
        """Get JSON schemas for all available tools."""
        schemas = []
        for tool in self.tools.values():
            schemas.append({
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.parameters
                }
            })
        return schemas
```

### Data Models and Schemas
```python
# agent/schemas.py
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Literal
from datetime import datetime
import uuid

class AgentConfig(BaseModel):
    """Agent configuration settings."""
    model: str = Field(default="claude-3-sonnet-20240229", description="LLM model to use")
    temperature: float = Field(default=0.7, ge=0.0, le=2.0, description="Model temperature")
    max_tokens: int = Field(default=4000, gt=0, description="Maximum response tokens")
    system_prompt: Optional[str] = Field(default=None, description="Custom system prompt")
    enabled_tools: List[str] = Field(default_factory=list, description="List of enabled tool names")
    sandbox_config: Dict[str, Any] = Field(default_factory=dict, description="Sandbox configuration")

class ToolCall(BaseModel):
    """Represents a tool call from the LLM."""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    type: Literal["function"] = "function"
    function: "FunctionCall"

class FunctionCall(BaseModel):
    """Function call details."""
    name: str = Field(description="Tool function name")
    arguments: str = Field(description="JSON string of function arguments")

class Message(BaseModel):
    """Chat message in a conversation thread."""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    thread_id: str
    role: Literal["user", "assistant", "system"]
    content: str
    tool_calls: Optional[List[ToolCall]] = None
    tool_results: Optional[List[Dict[str, Any]]] = None
    created_at: datetime = Field(default_factory=datetime.utcnow)
    metadata: Optional[Dict[str, Any]] = None

class Thread(BaseModel):
    """Conversation thread."""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_id: str
    title: str
    messages: List[Message] = Field(default_factory=list)
    agent_config: AgentConfig
    is_public: bool = False
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)
    metadata: Optional[Dict[str, Any]] = None

class CreateThreadRequest(BaseModel):
    """Request to create a new thread."""
    title: str = Field(min_length=1, max_length=200)
    agent_config: AgentConfig = Field(default_factory=AgentConfig)
    is_public: bool = False
    metadata: Optional[Dict[str, Any]] = None

class SendMessageRequest(BaseModel):
    """Request to send a message."""
    content: str = Field(min_length=1, max_length=10000)
    attachments: Optional[List[str]] = None
    metadata: Optional[Dict[str, Any]] = None

# Update forward references
ToolCall.model_rebuild()
```

### LLM Service Integration
```python
# services/llm.py
from typing import List, Dict, Any, Optional
import litellm
from litellm import completion, acompletion
import json

from agent.schemas import Message, ToolCall
from utils.exceptions import LLMError

class LLMService:
    """Service for integrating with various LLM providers."""
    
    def __init__(self):
        self.default_model = "claude-3-sonnet-20240229"
        self.providers = {
            "anthropic": ["claude-3-sonnet-20240229", "claude-3-haiku-20240307"],
            "openai": ["gpt-4-turbo", "gpt-3.5-turbo"],
            "groq": ["mixtral-8x7b-32768", "llama3-70b-8192"]
        }
    
    async def generate_response(
        self,
        messages: List[Dict[str, str]],
        tools: Optional[List[Dict[str, Any]]] = None,
        model: str = None,
        temperature: float = 0.7,
        max_tokens: int = 4000
    ) -> "LLMResponse":
        """Generate response from LLM provider."""
        
        try:
            # Use default model if none specified
            if not model:
                model = self.default_model
            
            # Prepare request parameters
            params = {
                "model": model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens
            }
            
            # Add tools if provided
            if tools:
                params["tools"] = tools
                params["tool_choice"] = "auto"
            
            # Make async call to LLM
            response = await acompletion(**params)
            
            # Parse response
            content = response.choices[0].message.content
            tool_calls = []
            
            if response.choices[0].message.tool_calls:
                for tool_call in response.choices[0].message.tool_calls:
                    tool_calls.append(ToolCall(
                        id=tool_call.id,
                        function=FunctionCall(
                            name=tool_call.function.name,
                            arguments=tool_call.function.arguments
                        )
                    ))
            
            return LLMResponse(
                content=content,
                tool_calls=tool_calls,
                model=model,
                usage=response.usage
            )
            
        except Exception as e:
            raise LLMError(f"LLM generation failed: {str(e)}")
    
    def get_available_models(self) -> Dict[str, List[str]]:
        """Get list of available models by provider."""
        return self.providers

class LLMResponse(BaseModel):
    """Response from LLM service."""
    content: str
    tool_calls: List[ToolCall] = Field(default_factory=list)
    model: str
    usage: Optional[Dict[str, int]] = None
```

### Sandbox Security and Isolation
```python
# sandbox/isolation.py
import docker
import asyncio
import uuid
from typing import Dict, Any, Optional
import tempfile
import os

from utils.exceptions import SandboxError

class Sandbox:
    """Represents an isolated execution environment."""
    
    def __init__(self, sandbox_id: str, container_id: str, workspace_path: str):
        self.sandbox_id = sandbox_id
        self.container_id = container_id
        self.workspace_path = workspace_path
        self.is_active = True
    
    async def execute_command(self, command: str, timeout: int = 30) -> Dict[str, Any]:
        """Execute a command in the sandbox."""
        if not self.is_active:
            raise SandboxError("Sandbox is not active")
        
        try:
            docker_client = docker.from_env()
            container = docker_client.containers.get(self.container_id)
            
            # Execute command with timeout
            result = container.exec_run(
                command,
                working_dir="/workspace",
                user="sandbox",
                environment={"HOME": "/workspace"}
            )
            
            return {
                "exit_code": result.exit_code,
                "output": result.output.decode("utf-8"),
                "success": result.exit_code == 0
            }
            
        except Exception as e:
            raise SandboxError(f"Command execution failed: {str(e)}")
    
    async def write_file(self, file_path: str, content: str) -> bool:
        """Write content to a file in the sandbox."""
        try:
            # Create temporary file
            with tempfile.NamedTemporaryFile(mode='w', delete=False) as temp_file:
                temp_file.write(content)
                temp_file_path = temp_file.name
            
            # Copy to container
            docker_client = docker.from_env()
            container = docker_client.containers.get(self.container_id)
            
            with open(temp_file_path, 'rb') as f:
                container.put_archive("/workspace", f.read())
            
            # Cleanup
            os.unlink(temp_file_path)
            
            return True
            
        except Exception as e:
            raise SandboxError(f"File write failed: {str(e)}")
    
    async def read_file(self, file_path: str) -> str:
        """Read content from a file in the sandbox."""
        try:
            docker_client = docker.from_env()
            container = docker_client.containers.get(self.container_id)
            
            # Read file content
            result = container.exec_run(f"cat {file_path}")
            
            if result.exit_code != 0:
                raise SandboxError(f"File not found: {file_path}")
            
            return result.output.decode("utf-8")
            
        except Exception as e:
            raise SandboxError(f"File read failed: {str(e)}")
    
    async def cleanup(self):
        """Clean up the sandbox resources."""
        try:
            docker_client = docker.from_env()
            container = docker_client.containers.get(self.container_id)
            container.stop()
            container.remove()
            self.is_active = False
            
        except Exception as e:
            print(f"Sandbox cleanup warning: {str(e)}")

class SandboxManager:
    """Manages sandbox lifecycle and resource allocation."""
    
    def __init__(self):
        self.active_sandboxes: Dict[str, Sandbox] = {}
        self.docker_client = docker.from_env()
    
    async def create_sandbox(self, thread_id: str) -> Sandbox:
        """Create a new isolated sandbox environment."""
        
        sandbox_id = f"suna-agent-{thread_id}-{uuid.uuid4().hex[:8]}"
        
        try:
            # Create container
            container = self.docker_client.containers.run(
                image="suna-agent-sandbox",
                name=sandbox_id,
                detach=True,
                mem_limit="512m",
                cpu_count=1,
                network_mode="bridge",
                working_dir="/workspace",
                user="sandbox",
                environment={
                    "PYTHONPATH": "/workspace",
                    "HOME": "/workspace"
                },
                volumes={
                    f"suna-workspace-{thread_id}": {
                        "bind": "/workspace",
                        "mode": "rw"
                    }
                },
                security_opt=["no-new-privileges:true"],
                cap_drop=["ALL"],
                cap_add=["CHOWN", "DAC_OVERRIDE", "SETUID", "SETGID"],
                read_only=False,
                tmpfs={
                    "/tmp": "noexec,nosuid,size=100m",
                    "/var/tmp": "noexec,nosuid,size=100m"
                }
            )
            
            # Create sandbox instance
            sandbox = Sandbox(
                sandbox_id=sandbox_id,
                container_id=container.id,
                workspace_path=f"/workspace"
            )
            
            # Store in active sandboxes
            self.active_sandboxes[thread_id] = sandbox
            
            return sandbox
            
        except Exception as e:
            raise SandboxError(f"Failed to create sandbox: {str(e)}")
    
    async def get_sandbox(self, thread_id: str) -> Optional[Sandbox]:
        """Get existing sandbox for thread."""
        return self.active_sandboxes.get(thread_id)
    
    async def cleanup_sandbox(self, thread_id: str):
        """Clean up sandbox for thread."""
        if thread_id in self.active_sandboxes:
            await self.active_sandboxes[thread_id].cleanup()
            del self.active_sandboxes[thread_id]
```

## Python Best Practices

### Code Style and Formatting
- **Formatter**: Black with line length 88
- **Import Sorting**: isort with profile=black
- **Type Hints**: Use throughout codebase
- **Docstrings**: Google-style docstrings
- **Naming**: snake_case for functions/variables, PascalCase for classes

### Error Handling
```python
# utils/exceptions.py
class SunaError(Exception):
    """Base exception for Suna application."""
    pass

class AgentError(SunaError):
    """Agent-related errors."""
    pass

class ToolError(SunaError):
    """Tool execution errors."""
    pass

class SandboxError(SunaError):
    """Sandbox-related errors."""
    pass

class LLMError(SunaError):
    """LLM service errors."""
    pass

# Error handling in API endpoints
@app.exception_handler(SunaError)
async def suna_error_handler(request: Request, exc: SunaError):
    return JSONResponse(
        status_code=400,
        content={"error": type(exc).__name__, "message": str(exc)}
    )
```

### Dependency Injection
```python
# services/__init__.py
from .auth import AuthService
from .llm import LLMService
from .storage import StorageService

# Dependency providers
async def get_auth_service() -> AuthService:
    return AuthService()

async def get_llm_service() -> LLMService:
    return LLMService()

async def get_storage_service() -> StorageService:
    return StorageService()
```

### Logging Configuration
```python
# utils/logging.py
import logging
import json
from datetime import datetime
from typing import Dict, Any

class StructuredLogger:
    """Structured logging for Suna backend."""
    
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self._setup_logger()
    
    def _setup_logger(self):
        handler = logging.StreamHandler()
        formatter = StructuredFormatter()
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO)
    
    def info(self, message: str, **kwargs):
        self.logger.info(message, extra=kwargs)
    
    def error(self, message: str, **kwargs):
        self.logger.error(message, extra=kwargs)

class StructuredFormatter(logging.Formatter):
    """JSON formatter for structured logs."""
    
    def format(self, record: logging.LogRecord) -> str:
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        
        # Add extra fields
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith('_'):
                log_data[key] = value
        
        return json.dumps(log_data)

# Usage
logger = StructuredLogger(__name__)
logger.info("Agent execution started", thread_id="123", user_id="456")
```

### Testing Patterns
```python
# tests/conftest.py
import pytest
import asyncio
from fastapi.testclient import TestClient
from unittest.mock import Mock, AsyncMock

from api import app
from services.auth import AuthService
from agent.agent_manager import AgentManager

@pytest.fixture
def client():
    """Test client for API endpoints."""
    return TestClient(app)

@pytest.fixture
def mock_auth_service():
    """Mock authentication service."""
    service = Mock(spec=AuthService)
    service.get_current_user = AsyncMock()
    return service

@pytest.fixture
def mock_agent_manager():
    """Mock agent manager."""
    manager = Mock(spec=AgentManager)
    manager.create_thread = AsyncMock()
    manager.process_message = AsyncMock()
    return manager

@pytest.fixture(scope="session")
def event_loop():
    """Create event loop for async tests."""
    loop = asyncio.new_event_loop()
    yield loop
    loop.close()

# tests/unit/test_agents.py
import pytest
from unittest.mock import Mock, AsyncMock

from agent.agent_manager import AgentManager
from agent.schemas import CreateThreadRequest, AgentConfig

@pytest.mark.asyncio
async def test_create_thread(mock_agent_manager):
    """Test thread creation."""
    
    # Setup
    request = CreateThreadRequest(
        title="Test Thread",
        agent_config=AgentConfig()
    )
    
    mock_agent_manager.create_thread.return_value = {
        "thread_id": "test-123",
        "status": "created"
    }
    
    # Execute
    result = await mock_agent_manager.create_thread("user-123", request)
    
    # Assert
    assert result["thread_id"] == "test-123"
    assert result["status"] == "created"
    mock_agent_manager.create_thread.assert_called_once_with("user-123", request)
```

### Performance Optimization
- **Async/Await**: Use throughout for I/O operations
- **Connection Pooling**: Database and Redis connections
- **Caching**: Redis for frequent queries
- **Background Tasks**: Celery for long-running operations
- **Resource Limits**: Sandbox containers and execution timeouts
