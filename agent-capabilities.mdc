---
description:
globs:
alwaysApply: false
---
# Suna Agent Capabilities

## Agent Tools Structure

```
Agent Tools & Capabilities:
├── Core Tools                        # Essential Agent Capabilities
│   ├── Browser Automation             # Playwright-based Web Control
│   │   ├── Page Navigation            # Visit URLs, handle redirects
│   │   ├── Element Interaction        # Click, type, scroll actions
│   │   ├── Data Extraction            # Scrape text, tables, images
│   │   ├── Form Automation            # Fill and submit forms
│   │   ├── Screenshot Capture         # Visual page documentation
│   │   └── Cookie/Session Management  # Maintain login sessions
│   ├── File Operations               # Document Management
│   │   ├── File Creation             # Create text, PDF, Excel files
│   │   ├── File Reading              # Parse various file formats
│   │   ├── File Modification         # Edit existing documents
│   │   ├── File Organization         # Directory management
│   │   ├── File Conversion           # Format transformations
│   │   └── File Upload/Download      # Transfer operations
│   ├── Code Execution                # Python Code Interpreter
│   │   ├── Script Execution          # Run Python code securely
│   │   ├── Data Analysis             # Pandas, NumPy operations
│   │   ├── Visualization             # Matplotlib, charts
│   │   ├── API Testing               # HTTP requests testing
│   │   ├── Package Installation      # Pip package management
│   │   └── Error Handling            # Exception management
│   ├── Web Search                    # Enhanced Search Capabilities
│   │   ├── General Search            # Web-wide information retrieval
│   │   ├── Academic Search           # Research paper discovery
│   │   ├── News Search               # Current events and trends
│   │   ├── Image Search              # Visual content discovery
│   │   ├── Video Search              # Video content discovery
│   │   └── Local Search              # Location-based results
│   └── API Integration               # External Service Connections
│       ├── REST API Calls            # HTTP method support
│       ├── Authentication            # OAuth, API key management
│       ├── Rate Limiting             # Request throttling
│       ├── Response Parsing          # JSON/XML processing
│       ├── Error Handling            # Retry logic and fallbacks
│       └── Webhook Management        # Event-driven integrations
├── Data Providers (MCP)              # External Data Sources
│   ├── LinkedIn Integration          # Professional Network Data
│   │   ├── Profile Search            # Find professionals by criteria
│   │   ├── Company Research          # Business information gathering
│   │   ├── Job Listings              # Employment opportunities
│   │   ├── Industry Analysis         # Market intelligence
│   │   ├── Connection Mapping        # Network visualization
│   │   └── Content Publishing        # Post automation
│   ├── Tavily Search                 # Advanced Web Search
│   │   ├── Real-time Results         # Current information retrieval
│   │   ├── Source Verification       # Credibility assessment
│   │   ├── Semantic Search           # Context-aware queries
│   │   ├── Multi-language Support    # Global content access
│   │   ├── Domain Filtering          # Targeted source selection
│   │   └── Fact Checking             # Information validation
│   ├── Firecrawl Scraping           # Web Content Extraction
│   │   ├── Full Page Scraping        # Complete content extraction
│   │   ├── Structured Data           # Table and list parsing
│   │   ├── JavaScript Rendering      # Dynamic content handling
│   │   ├── Anti-bot Circumvention    # Stealth scraping techniques
│   │   ├── Batch Processing          # Multiple URL handling
│   │   └── Content Cleaning          # Noise removal and formatting
│   ├── Amazon Integration            # E-commerce Data
│   │   ├── Product Research          # Item details and pricing
│   │   ├── Review Analysis           # Customer sentiment mining
│   │   ├── Price Tracking            # Historical pricing data
│   │   ├── Inventory Monitoring      # Stock level tracking
│   │   ├── Competitor Analysis       # Market comparison
│   │   └── Sales Intelligence        # Performance metrics
│   └── RapidAPI Services             # Extensive API Ecosystem
│       ├── Social Media APIs         # Platform integrations
│       ├── Financial Data APIs       # Market and economic data
│       ├── Weather APIs              # Meteorological information
│       ├── Translation APIs          # Multi-language support
│       ├── Image/Video APIs          # Media processing services
│       └── Custom Integrations       # Specialized business APIs
├── Specialized Capabilities          # Domain-specific Features
│   ├── Computer Vision               # Image Analysis
│   │   ├── OCR (Text Recognition)    # Extract text from images
│   │   ├── Object Detection          # Identify items in images
│   │   ├── Facial Recognition        # People identification
│   │   ├── Chart/Graph Reading       # Data visualization parsing
│   │   ├── Document Analysis         # Structured document parsing
│   │   └── Quality Assessment        # Image quality evaluation
│   ├── Natural Language Processing   # Text Analysis
│   │   ├── Sentiment Analysis        # Emotion detection
│   │   ├── Entity Extraction         # Named entity recognition
│   │   ├── Language Detection        # Automatic language identification
│   │   ├── Text Summarization        # Content condensation
│   │   ├── Translation               # Multi-language conversion
│   │   └── Content Classification    # Topic categorization
│   ├── Data Processing               # Information Manipulation
│   │   ├── CSV/Excel Analysis        # Spreadsheet operations
│   │   ├── Database Queries          # SQL execution
│   │   ├── Statistical Analysis      # Mathematical computations
│   │   ├── Data Visualization        # Chart and graph creation
│   │   ├── Data Cleaning             # Quality improvement
│   │   └── Format Conversion         # Data transformation
│   └── Communication                 # External Interactions
│       ├── Email Automation          # Message composition and sending
│       ├── SMS/Messaging             # Text communication
│       ├── Calendar Management       # Scheduling operations
│       ├── Video Conferencing        # Meeting automation
│       ├── Social Media Posting      # Content publishing
│       └── Notification Systems      # Alert mechanisms
└── Security & Compliance             # Safety and Governance
    ├── Sandbox Isolation             # Secure execution environment
    ├── Access Control                # Permission management
    ├── Data Privacy                  # Information protection
    ├── Audit Logging                 # Activity tracking
    ├── Rate Limiting                 # Resource protection
    └── Content Filtering             # Safety mechanisms
```

## Use Case Categories

### 1. Business Intelligence & Research
**Capabilities**: Market analysis, competitor research, industry reports
**Tools Used**: Web search, LinkedIn, Firecrawl, data analysis
**Example Scenarios**:
- Comprehensive competitor analysis with market sizing
- Industry landscape mapping with key player identification
- Market trend analysis with supporting data visualization
- Customer sentiment analysis across multiple platforms
- Investment opportunity research with financial metrics

**Implementation Pattern**:
```python
# Business Intelligence Agent Configuration
business_intelligence_config = {
    "enabled_tools": [
        "web_search",
        "linkedin_provider", 
        "firecrawl_scraping",
        "data_analysis",
        "file_operations"
    ],
    "system_prompt": "You are a business intelligence analyst...",
    "search_parameters": {
        "depth": "comprehensive",
        "sources": ["news", "financial", "industry_reports"],
        "verification": True
    }
}
```

### 2. Lead Generation & Sales Prospecting
**Capabilities**: Professional network analysis, contact discovery, outreach automation
**Tools Used**: LinkedIn, web search, email automation, data processing
**Example Scenarios**:
- LinkedIn prospect identification with qualification criteria
- Contact information discovery and verification
- Personalized outreach message generation
- Lead scoring based on multiple data points
- CRM integration and pipeline management

**Implementation Pattern**:
```python
# Sales Prospecting Agent Configuration
prospecting_config = {
    "enabled_tools": [
        "linkedin_provider",
        "web_search",
        "email_automation",
        "data_processing",
        "crm_integration"
    ],
    "filters": {
        "industry": ["technology", "healthcare"],
        "company_size": "50-500",
        "location": "San Francisco Bay Area",
        "job_titles": ["CTO", "VP Engineering", "Head of Product"]
    }
}
```

### 3. Content Creation & Research
**Capabilities**: Information gathering, content synthesis, document generation
**Tools Used**: Web search, Tavily, file operations, NLP, data visualization
**Example Scenarios**:
- Comprehensive research reports with citations
- Blog post creation with supporting data
- Social media content calendars
- Technical documentation generation
- Educational material development

**Implementation Pattern**:
```python
# Content Research Agent Configuration
content_config = {
    "enabled_tools": [
        "tavily_search",
        "web_search", 
        "file_operations",
        "nlp_processing",
        "data_visualization"
    ],
    "content_parameters": {
        "research_depth": "comprehensive",
        "citation_style": "APA",
        "fact_checking": True,
        "source_diversity": True
    }
}
```

### 4. E-commerce & Product Analysis
**Capabilities**: Product research, price monitoring, review analysis, market intelligence
**Tools Used**: Amazon integration, web scraping, data analysis, visualization
**Example Scenarios**:
- Product competitive analysis with pricing trends
- Customer review sentiment analysis
- Market opportunity identification
- Inventory optimization recommendations
- Supplier research and evaluation

**Implementation Pattern**:
```python
# E-commerce Analysis Agent Configuration
ecommerce_config = {
    "enabled_tools": [
        "amazon_integration",
        "firecrawl_scraping",
        "data_analysis",
        "sentiment_analysis",
        "price_tracking"
    ],
    "analysis_parameters": {
        "categories": ["electronics", "home_garden"],
        "price_range": {"min": 50, "max": 500},
        "review_threshold": 100,
        "time_frame": "6_months"
    }
}
```

### 5. Travel & Event Planning
**Capabilities**: Itinerary creation, booking research, weather analysis, logistics planning
**Tools Used**: Web search, APIs, data processing, calendar management
**Example Scenarios**:
- Comprehensive trip planning with accommodations and activities
- Event venue research and booking coordination
- Weather-based activity recommendations
- Budget optimization with cost analysis
- Group coordination and communication

**Implementation Pattern**:
```python
# Travel Planning Agent Configuration
travel_config = {
    "enabled_tools": [
        "web_search",
        "weather_api",
        "booking_apis",
        "calendar_management",
        "budget_analysis"
    ],
    "planning_parameters": {
        "trip_type": "business",
        "budget_range": {"min": 2000, "max": 5000},
        "preferences": ["high_rating", "central_location"],
        "group_size": 8
    }
}
```

### 6. Academic & Scientific Research
**Capabilities**: Literature review, data analysis, citation management, report generation
**Tools Used**: Academic search, data processing, visualization, document management
**Example Scenarios**:
- Systematic literature reviews with meta-analysis
- Research paper discovery and summarization
- Data collection and statistical analysis
- Grant application research and writing
- Peer review and collaboration facilitation

**Implementation Pattern**:
```python
# Academic Research Agent Configuration
academic_config = {
    "enabled_tools": [
        "academic_search",
        "citation_management",
        "statistical_analysis",
        "document_generation",
        "collaboration_tools"
    ],
    "research_parameters": {
        "databases": ["pubmed", "arxiv", "ieee"],
        "publication_years": "2020-2024",
        "citation_minimum": 10,
        "methodology": "systematic_review"
    }
}
```

## Tool Integration Patterns

### Sequential Tool Execution
```python
# Example: Market Research Workflow
workflow = [
    {
        "tool": "web_search",
        "parameters": {"query": "renewable energy market trends 2024"},
        "output_to": "search_results"
    },
    {
        "tool": "linkedin_provider", 
        "parameters": {"search": "renewable energy executives"},
        "output_to": "industry_contacts"
    },
    {
        "tool": "data_analysis",
        "parameters": {"data": "search_results", "analysis_type": "trend"},
        "output_to": "trend_analysis"
    },
    {
        "tool": "file_operations",
        "parameters": {
            "action": "create_report",
            "data": ["trend_analysis", "industry_contacts"],
            "format": "pdf"
        }
    }
]
```

### Parallel Tool Execution
```python
# Example: Comprehensive Company Research
parallel_tasks = [
    {
        "tool": "web_search",
        "parameters": {"query": "company_name financial performance"}
    },
    {
        "tool": "linkedin_provider",
        "parameters": {"company": "company_name", "data_type": "employees"}
    },
    {
        "tool": "firecrawl_scraping",
        "parameters": {"url": "company_website", "extract": "full_content"}
    },
    {
        "tool": "tavily_search",
        "parameters": {"query": "company_name news recent"}
    }
]
```

### Conditional Tool Logic
```python
# Example: Adaptive Research Strategy
def adaptive_research_workflow(topic, depth="standard"):
    base_tools = ["web_search", "tavily_search"]
    
    if depth == "comprehensive":
        base_tools.extend(["academic_search", "expert_interviews"])
    
    if topic in ["business", "industry"]:
        base_tools.extend(["linkedin_provider", "financial_apis"])
    
    if topic in ["products", "ecommerce"]:
        base_tools.extend(["amazon_integration", "review_analysis"])
    
    return base_tools
```

## Data Provider Specifications

### LinkedIn Provider
**Authentication**: OAuth 2.0 or credentials-based
**Rate Limits**: 100 requests/hour for search, 500/hour for profile views
**Capabilities**:
- Advanced people search with filters (location, industry, company, role)
- Company research and employee mapping
- Job listings and market analysis
- Content publishing and engagement tracking
- Network analysis and connection recommendations

**Usage Example**:
```python
linkedin_params = {
    "search_type": "people",
    "keywords": "machine learning engineer",
    "location": "San Francisco",
    "current_company": "tech startups",
    "experience_level": "mid-senior",
    "limit": 50
}
```

### Tavily Search Provider
**Authentication**: API key
**Rate Limits**: 1000 queries/month on free tier
**Capabilities**:
- Real-time web search with source attribution
- Academic and news-specific search modes
- Multi-language query support
- Fact-checking and source verification
- Content summarization and extraction

**Usage Example**:
```python
tavily_params = {
    "query": "artificial intelligence regulations Europe 2024",
    "search_depth": "advanced",
    "include_domains": ["europa.eu", "ec.europa.eu"],
    "max_results": 20,
    "include_raw_content": True
}
```

### Firecrawl Provider
**Authentication**: API key
**Rate Limits**: 500 pages/month on free tier
**Capabilities**:
- JavaScript-rendered page scraping
- Structured data extraction (tables, lists, forms)
- Anti-detection mechanisms
- Batch URL processing
- Content cleaning and formatting

**Usage Example**:
```python
firecrawl_params = {
    "url": "https://example.com/data-page",
    "formats": ["markdown", "html"],
    "wait_for": "networkidle",
    "extract": {
        "tables": True,
        "images": True,
        "links": True
    }
}
```

### Amazon Provider
**Authentication**: API key or affiliate credentials
**Rate Limits**: Varies by endpoint
**Capabilities**:
- Product search and details retrieval
- Price history and tracking
- Review analysis and sentiment scoring
- Inventory and availability monitoring
- Competitive analysis and market insights

**Usage Example**:
```python
amazon_params = {
    "search_query": "wireless bluetooth headphones",
    "category": "electronics",
    "price_range": {"min": 50, "max": 200},
    "min_reviews": 100,
    "rating_threshold": 4.0,
    "include_variations": True
}
```

## Security and Compliance

### Sandbox Security Features
- **Process Isolation**: Each agent runs in isolated Docker containers
- **Resource Limits**: CPU, memory, and disk space restrictions
- **Network Controls**: Restricted internet access with allowlist
- **File System Isolation**: Sandboxed file operations
- **Time Limits**: Execution timeout enforcement

### Data Privacy Protection
- **Encryption**: All data encrypted in transit and at rest
- **Access Controls**: Role-based permissions for sensitive operations
- **Audit Logging**: Complete activity tracking and monitoring
- **Data Retention**: Configurable data lifecycle policies
- **GDPR Compliance**: Right to deletion and data portability

### Rate Limiting and Fair Use
- **API Rate Limits**: Per-user and per-tool request throttling
- **Resource Quotas**: CPU and memory usage limits
- **Cost Controls**: Budget limits for paid API integrations
- **Abuse Prevention**: Automated detection and blocking

## Performance Optimization

### Caching Strategies
- **Search Result Caching**: Temporary storage of search results
- **API Response Caching**: Cached responses for expensive API calls
- **File Processing Cache**: Preprocessed document storage
- **Session Management**: Persistent browser sessions for efficiency

### Parallel Processing
- **Concurrent Tool Execution**: Multiple tools running simultaneously
- **Batch Operations**: Bulk processing for similar tasks
- **Asynchronous Operations**: Non-blocking I/O for improved performance
- **Queue Management**: Background task processing

### Error Handling and Resilience
- **Retry Logic**: Automatic retry with exponential backoff
- **Fallback Mechanisms**: Alternative approaches when primary tools fail
- **Circuit Breakers**: Prevent cascade failures in tool chains
- **Graceful Degradation**: Partial results when some tools are unavailable

## Tool Development Guidelines

### Creating Custom Tools
```python
from agent.executor import BaseTool
from typing import Dict, Any

class CustomTool(BaseTool):
    @property
    def name(self) -> str:
        return "custom_tool_name"
    
    @property 
    def description(self) -> str:
        return "Description of what this tool does"
    
    @property
    def parameters(self) -> Dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "input_param": {
                    "type": "string",
                    "description": "Parameter description"
                }
            },
            "required": ["input_param"]
        }
    
    async def execute(self, sandbox: Sandbox, **kwargs) -> Any:
        # Tool implementation
        return {"result": "tool output"}
```

### MCP Integration
```python
# MCP Provider Example
from mcp_local.providers.base import MCPProvider

class CustomMCPProvider(MCPProvider):
    def __init__(self):
        super().__init__("custom_provider")
    
    async def get_tools(self):
        return [
            {
                "name": "custom_function",
                "description": "Custom functionality",
                "parameters": {...}
            }
        ]
    
    async def call_tool(self, name: str, arguments: dict):
        if name == "custom_function":
            return await self._custom_function(**arguments)
```

### Testing Tools
```python
# Tool Testing Example
import pytest
from unittest.mock import Mock

@pytest.mark.asyncio
async def test_custom_tool():
    tool = CustomTool()
    mock_sandbox = Mock()
    
    result = await tool.execute(
        sandbox=mock_sandbox,
        input_param="test_value"
    )
    
    assert result["result"] == "expected_output"
```
